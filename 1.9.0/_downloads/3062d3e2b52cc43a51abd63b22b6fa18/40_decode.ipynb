{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Decoding real-time data\n\n.. include:: ./../../links.inc\n\nThis example demonstrates how to decode real-time data using [MNE-Python](mne stable_)\nand [Scikit-learn](sklearn stable_). We will stream the ``sample_audvis_raw.fif``\nfile from MNE's sample dataset with a :class:`~mne_lsl.player.PlayerLSL`, process the\nsignal through a :class:`~mne_lsl.stream.StreamLSL`, and decode the epochs created with\n:class:`~mne_lsl.stream.EpochsStream`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport uuid\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom mne.decoding import Vectorizer\nfrom mne.io import read_raw_fif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import ShuffleSplit, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom mne_lsl.datasets import sample\nfrom mne_lsl.player import PlayerLSL\nfrom mne_lsl.stream import EpochsStream, StreamLSL\n\nfname = sample.data_path() / \"mne-sample\" / \"sample_audvis_raw.fif\"\nraw = read_raw_fif(fname, preload=False).pick((\"meg\", \"stim\")).load_data()\nsource_id = uuid.uuid4().hex\nplayer = PlayerLSL(raw, chunk_size=200, name=\"real-time-decoding\", source_id=source_id)\nplayer.start()\nplayer.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Signal processing\n\nWe will apply minimal signal processing to the data. First, only the gradiometers will\nbe used for decoding, thus other channels are removed. Then we mark bad channels and\napplying a low-pass filter at 40 Hz.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stream = StreamLSL(bufsize=5, name=\"real-time-decoding\", source_id=source_id)\nstream.connect(acquisition_delay=0.1, processing_flags=\"all\")\nstream.info[\"bads\"] = [\"MEG 2443\"]\nstream.pick((\"grad\", \"stim\")).filter(None, 40, picks=\"grad\")\nstream.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch the signal\n\nNext, we will create epochs around the event ``1`` (audio left) and ``3`` (visual\nleft).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = EpochsStream(\n    stream,\n    bufsize=10,\n    event_id=dict(audio_left=1, visual_left=3),\n    event_channels=\"STI 014\",\n    tmin=-0.2,\n    tmax=0.5,\n    baseline=(None, 0),\n    reject=dict(grad=4000e-13),  # unit: T / m (gradiometers)\n).connect(acquisition_delay=0.1)\nepochs.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the classifier\n\nWe will use a :class:`~sklearn.linear_model.LogisticRegression` classifier to decode\nthe epochs.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The object :class:`~mne.decoding.Vectorizer` is used to transform the epochs in a\n    2D array of shape (n_epochs, n_features). It's simply reshapes the epochs data\n    with:\n\n```python\ndata = epochs.get_data()\ndata = data.reshape(data.shape[0], -1)</p></div>\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorizer = Vectorizer()\nscaler = StandardScaler()\nclf = LogisticRegression()\nclassifier = Pipeline([(\"vector\", vectorizer), (\"scaler\", scaler), (\"svm\", clf)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decode\n\nFirst, we will wait for a minimum number of epochs to be available. Then, the\nclassifier will be trained for the first time and future epochs will be used to\nretrain the classifier every 5 epochs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "min_epochs = 10\nwhile epochs.n_new_epochs < min_epochs:\n    time.sleep(0.5)\n\n# prepare figure to plot classifiation score\nif not plt.isinteractive():\n    plt.ion()\nfig, ax = plt.subplots()\nax.set_xlabel(\"Epochsn n\u00b0\")\nax.set_ylabel(\"Classification score (% correct)\")\nax.set_title(\"Real-time decoding\")\nax.set_xlim([min_epochs, 50])\nax.set_ylim([30, 105])\nax.axhline(50, color=\"k\", linestyle=\"--\", label=\"Chance level\")\nplt.show()\n\n# decoding loop\nscores_x, scores, std_scores = [], [], []\nwhile True:\n    if len(scores_x) != 0 and 50 <= scores_x[-1]:\n        break\n    n_epochs = epochs.n_new_epochs\n    if n_epochs == 0 or n_epochs % 5 != 0:\n        time.sleep(0.5)  # give time to the streaming and acquisition threads\n        continue\n\n    if len(scores_x) == 0:  # first training\n        X = epochs.get_data(n_epochs=n_epochs)\n        y = epochs.events[-n_epochs:]\n    else:\n        X = np.concatenate((X, epochs.get_data(n_epochs=n_epochs)), axis=0)\n        y = np.concatenate((y, epochs.events[-n_epochs:]))\n    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n    scores_t = cross_val_score(classifier, X, y, cv=cv, n_jobs=1) * 100\n    std_scores.append(scores_t.std())\n    scores.append(scores_t.mean())\n    scores_x.append(scores_x[-1] + n_epochs if len(scores_x) != 0 else n_epochs)\n\n    # update figure\n    ax.plot(scores_x[-2:], scores[-2:], \"-x\", color=\"b\")\n    hyp_limits = (\n        np.asarray(scores[-2:]) - np.asarray(std_scores[-2:]),\n        np.asarray(scores[-2:]) + np.asarray(std_scores[-2:]),\n    )\n    fill = ax.fill_between(\n        scores_x[-2:], y1=hyp_limits[0], y2=hyp_limits[1], color=\"b\", alpha=0.5\n    )\n    plt.pause(0.1)\n    plt.draw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Free resources\n\nWhen you are done with a :class:`~mne_lsl.player.PlayerLSL`,\n:class:`~mne_lsl.stream.StreamLSL` or :class:`~mne_lsl.stream.EpochsStream`, don't\nforget to free the resources they use to continuously mock an LSL stream or receive\nnew data from an LSL stream.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stream.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "player.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}